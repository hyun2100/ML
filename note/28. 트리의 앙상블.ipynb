{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  sugar    pH  class\n",
       "0      9.4    1.9  3.51    0.0\n",
       "1      9.8    2.6  3.20    0.0\n",
       "2      9.8    2.3  3.26    0.0\n",
       "3      9.8    1.9  3.16    0.0\n",
       "4      9.4    1.9  3.51    0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wine = pd.read_csv('../data/wine.csv')\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wine.iloc[:, :3].to_numpy()\n",
    "target = wine.iloc[:, 3].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.4 ,  1.9 ,  3.51],\n",
       "       [ 9.8 ,  2.6 ,  3.2 ],\n",
       "       [ 9.8 ,  2.3 ,  3.26],\n",
       "       ...,\n",
       "       [ 9.4 ,  1.2 ,  2.99],\n",
       "       [12.8 ,  1.1 ,  3.34],\n",
       "       [11.8 ,  0.8 ,  3.26]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    data,\n",
    "    target, \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973541965122431 0.8903229806766861\n"
     ]
    }
   ],
   "source": [
    "# RandomForest Model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42, n_estimators=100)\n",
    "\n",
    "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23183515 0.50059756 0.26756729]\n"
     ]
    }
   ],
   "source": [
    "# 주요 Feature 확인\n",
    "\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8945545507023283\n"
     ]
    }
   ],
   "source": [
    "# 부트스트랩 결정시 남는 샘플(oob out of back)도 특성으로 구분할 수 있다.\n",
    "\n",
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Extra Tree(엑스트라 트리)\n",
    "- 기본적으로 100개의 트리를 사용\n",
    "- 노드 분할시 특성(Feature)의 제곱근을 갯수로 사용\n",
    "- 특성 선택을 랜덤하게 선택\n",
    "- 특성의 선택을 랜덤하게 하므로, 속도는 랜덤포레스트보다 빠르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974503966084433 0.8887848893166506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23183515 0.50059756 0.26756729]\n"
     ]
    }
   ],
   "source": [
    "# 주요 Feature 확인\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Gradient Boosting(그래디언트 부스팅)\n",
    "- 가장 유명한 알고리즘중 하나이다.\n",
    "- 경사하강법처럼 손실함수를 사용.\n",
    "- 손실함수를 보고 트리를 추가하여 최적의 값을 도출하는 방법\n",
    "- Decisino Tree Regressor를 사용하여 손실함수를 계산한고 이를 계속 낮추기 위해 트리를 추가하는 구조\n",
    "- 경사를 이동하면서 경사의 이동거리를 제어하는 learning-rate(기본 : 0.1)을 사용한다.  \n",
    "- max depth를 3으로 제어하여 깊이가 낮으므로, 과대적합이 방지된다.\n",
    "- 단점은 손실함수를 보고 트리를 추가하면서 진행하는 모델이므로 병렬처리(n_jobs)를 할수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8881086892152563 0.8720430147331015\n"
     ]
    }
   ],
   "source": [
    "# 기본값으로 모델 구성\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8881086892152563 0.8720430147331015\n"
     ]
    }
   ],
   "source": [
    "# 기본값 확인\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42, n_estimators=100, learning_rate=0.1)\n",
    "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8872908264055726 0.8720428296438882\n"
     ]
    }
   ],
   "source": [
    "# 기본값 변경\n",
    "gb = GradientBoostingClassifier(random_state=42, n_estimators=500, learning_rate=0.02)\n",
    "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12190897 0.7416382  0.13645283]\n"
     ]
    }
   ],
   "source": [
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 히스토그램 기반 그래디언트 부스팅(Histogram gradient boosting)\n",
    "- 훈련데이터를 256개의 구간으로 나누어서 훈련시키는 방법\n",
    "- 특성의 범위가 제한되어 빠른 속도를 제공함.\n",
    "- 제한된 구간이므로 과대적합을 방지.\n",
    "- 아직은 실험단계인 모델."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321723946453317 0.8801241948619236\n"
     ]
    }
   ],
   "source": [
    "# 모델 새성\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# * 번외 기능 *\n",
    "### Permutation Importance(치환 중요도)\n",
    "- feature별 sample을 섞어서 계산을 한 후에 원래 sample들과의 차이를 계산하여 차이가 많이 나는 featrue가 중요하다는 판단을 한다. \n",
    "- 즉, 어느 Feature가 중요한지 파악하는 방법.\n",
    "- 어떤 모델에도 사용 가능하며, 특성을 파악하는 주요 기준으로 사용된다. 권장사항\n",
    "- Dataset을 구성할 때 필수적으로 사용되는 모델이며, 수집한 데이터의 중요도 파악에 많이 사용되며 영향이 없는 Feature는 속도만 축내는 꼴이다..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08876275 0.23438522 0.08027708]\n"
     ]
    }
   ],
   "source": [
    "# Train경우 확인\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "hgb.fit(train_input, train_target)\n",
    "result = permutation_importance(hgb, train_input, train_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'importances_mean': array([0.08876275, 0.23438522, 0.08027708]), 'importances_std': array([0.00382333, 0.00401363, 0.00477012]), 'importances': array([[0.08793535, 0.08350972, 0.08908986, 0.08312488, 0.09274581,\n",
      "        0.08755051, 0.08601116, 0.09601693, 0.09082163, 0.09082163],\n",
      "       [0.22782374, 0.23590533, 0.23936887, 0.23436598, 0.23725226,\n",
      "        0.23436598, 0.23359631, 0.23398114, 0.23994612, 0.22724649],\n",
      "       [0.08581874, 0.08601116, 0.08062344, 0.07504329, 0.08427939,\n",
      "        0.07792957, 0.07234943, 0.07465846, 0.08139311, 0.08466423]])}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> sugar의 경우 Feature를 무작위로 섞으면 23%만큼 정확도가 떨어진다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### XGBoost\n",
    "- kaggle에서 많이 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558403027491312 0.8782000074035686\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "            tree_method = 'hist',\n",
    "            random_state = 42, \n",
    "            eval_metric = 'logloss',\n",
    ")\n",
    "\n",
    "scores =  cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tjAKA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
